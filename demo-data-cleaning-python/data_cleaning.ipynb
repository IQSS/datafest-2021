{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Datafest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUW1STSbOhPH"
      },
      "source": [
        "# DAY 1: Acquiring and cleaning data (Python)\n",
        "\n",
        "## Acquiring data from APIs\n",
        "\n",
        "Hopefully you were able to attend yesterday's session on using APIs to acquire data, but here's a quick refresher on the dataset if not.\n",
        "\n",
        "For the project we’ll pursue during DataFest, we’re going to access data stored on the Harvard Dataverse. A Dataverse is open source software for repositing research data. Once data is stored in a Dataverse, it can be accessed programmatically using the Dataverse API. We will use the Python package `dataverse` as an interface for the Dataverse API.\n",
        "\n",
        "Here are three COVID-19 datasets from the Harvard Dataverse:\n",
        "\n",
        "* [US data on COVID-19 cases and deaths, daily at state-level or county-level](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HIDLTK)\n",
        "* [US data on COVID-19 cases and deaths, daily at metropolitan-level](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/5B8YM8)\n",
        "* [World data on COVID-19 cases and deaths, daily at country-level](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L20LOT)\n",
        "\n",
        "We're going to use daily data on COVID-19 cases from the U.S. at the state-level (from dataset #1 above). These data span the period from January 21st 2020 until November 29th 2020 for each U.S. state (and the District of Columbia). If you wish, you may choose to use one of the other datasets for your project.\n",
        "\n",
        "We can use the pyDataverse module as an interface for the API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlkqXEiHPHIX"
      },
      "source": [
        "# Install pyDataverse, if it isn't already there\n",
        "!pip install pyDataverse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yAvRT57POSf"
      },
      "source": [
        "# Import Dataverse modules\n",
        "from pyDataverse.api import Api\n",
        "from pyDataverse.models import Dataverse\n",
        "\n",
        "# Import the usual data science suspects\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# BytesIO so we can load the API response into pandas\n",
        "from io import BytesIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm24Uv9yO3aB"
      },
      "source": [
        "# get the digital object identifier for the Dataverse dataset\n",
        "DOI = \"doi:10.7910/DVN/HIDLTK\"\n",
        "\n",
        "# establish connection\n",
        "base_url = 'https://dataverse.harvard.edu/'\n",
        "api = Api(base_url)\n",
        "print(api.status)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPjuPQmOPbTM"
      },
      "source": [
        "covid = api.get_dataset(DOI)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAJ7KgD7Pe0G"
      },
      "source": [
        "# Get a list of files, iterate through it, and show what's available\n",
        "covid_files_list = covid.json()['data']['latestVersion']['files']\n",
        "\n",
        "# view available files\n",
        "for fileObject in covid_files_list:\n",
        "    print(\"File name is {}; id is {}\".format(fileObject[\"dataFile\"][\"filename\"], fileObject[\"dataFile\"][\"id\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6w9RW1oPhTs"
      },
      "source": [
        "# get data file for COVID-19 cases\n",
        "US_states_cases_file = api.get_datafile(\"4201597\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxAO9bOEzt8q"
      },
      "source": [
        "## Read the data into pandas\n",
        "\n",
        "Here ends the API recap and begins data cleanup. We'll use the Python library `pandas` to work with our data. The first thing we'll do is read it, but our code looks a bit different from what you'd probably use on your own data. Normally, this is what you'll do:\n",
        "\n",
        "    df = pd.read_csv(\"some-file.csv\")\n",
        "\n",
        "Where `df` is the dataframe object you create and `some-file.csv` is the file you want to read, either as an absolute file path or one relative to the location you're running your notebook in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HicpDuqGPtQT"
      },
      "source": [
        "# Read the file into a pandas dataframe using BytesIO\n",
        "US_states_cases = pd.read_csv(BytesIO(US_states_cases_file.content),sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drVYHqVpP5Wo"
      },
      "source": [
        "# Take a look at the top of the dataframe\n",
        "US_states_cases.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMw9i73M0gIO"
      },
      "source": [
        "# Take a look at the bottom of the dataframe\n",
        "US_states_cases.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5nNkV1R0Q3"
      },
      "source": [
        "# Cleaning data\n",
        "\n",
        "## COVID-19 cases data\n",
        "\n",
        "The COVID-19 cases data are in wide format, with individual columns for each day’s case counts. To visualize and analyze the data, it will be much easier to reshape the data so that it is organized in long format, with a single column for case counts and another column indicating the date those counts are associated with.\n",
        "\n",
        "In addition, it will be useful to derive some time-related variables (e.g., day of year, week of year) from the dates. Finally, we should transform our cumulative case counts into regular counts and create some rate variables by normalizing by population count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx9q5EnRUdIv"
      },
      "source": [
        "# \"melt\" the dataframe into a tall format. Hover over `melt` in Google Colab to see a description of the function and parameters\n",
        "\n",
        "US_states_cases_tall = pd.melt(US_states_cases,\n",
        "        id_vars=['fips','NAME','POP70','HHD70','POP80','HHD80','POP90','HHD90','POP00','HHD00','POP10','HHD10'],\n",
        "        var_name='date', value_name='cases_cumulative')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABRN9eZG2R1b"
      },
      "source": [
        "US_states_cases_tall.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhR40Pt879z0"
      },
      "source": [
        "US_states_cases_tall[US_states_cases_tall.NAME=='Massachusetts'].head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhNb12Y7EbOU"
      },
      "source": [
        "# Suppress scientific notation\n",
        "# I figured this out by copying from https://stackoverflow.com/questions/17737300/suppressing-scientific-notation-in-pandas\n",
        "pd.options.display.float_format = '{:.2f}'.format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGFs4Zj-D4DS"
      },
      "source": [
        "US_states_cases_tall.cases_cumulative.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3iVZFLt4wGS"
      },
      "source": [
        "Now that we've re-shaped the data, we'll want to add some new columns, derived from the data we have. The first thing we want to do is get the count of cases recorded on a given day, derived from the change in the cumulative count recorded.\n",
        "\n",
        "To do that, we'll first sort by state and date, to put everything in order. We can sort by date even though the dates aren't stored as a date data type because this dataset uses [ISO 8601](https://www.iso.org/iso-8601-date-and-time-format.html), which is the [correct way to represent dates](https://xkcd.com/1179/).\n",
        "\n",
        "Then we'll reset the index, since we no longer care how things were ordered before.\n",
        "\n",
        "Last but not least, we'll group by state and apply a function using `shift` to get the value of the cumulative count in the previous row and subtract it from the current row's value.\n",
        "\n",
        "Pay attention to all of the `inplace` keywords here. Pandas functions usually return a new dataframe rather than modifying one in place, and assigning a modified dataframe back to the same variable name can cause unexpected behavior, so modifying your data in place is often the way to go."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwEBA-BnVE40"
      },
      "source": [
        "US_states_cases_tall.sort_values(['fips', 'date'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GBTq53HXw4i"
      },
      "source": [
        "US_states_cases_tall.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMj0WOLe5TzY"
      },
      "source": [
        "# create cases counts\n",
        "US_states_cases_tall['cases_count'] = US_states_cases_tall.groupby('NAME').cases_cumulative.apply(lambda x: x - x.shift(1)).fillna(0)\n",
        "US_states_cases_tall.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfBJqt70c6-X"
      },
      "source": [
        "# Are there any negative case counts?\n",
        "US_states_cases_tall[US_states_cases_tall.cases_count < 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAddVVrXdT8I"
      },
      "source": [
        "# Are the negative case counts real?\n",
        "US_states_cases_tall.loc[6818:6820]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QgLHdkXdj0V"
      },
      "source": [
        "# tidy-up negative counts\n",
        "US_states_cases_tall[\"cases_count_pos\"] = np.where(US_states_cases_tall[\"cases_count\"] < 0, 0, US_states_cases_tall[\"cases_count\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b83RvkOhHVLN"
      },
      "source": [
        "Now we'll get some more information about the date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD74tXR3YAEc"
      },
      "source": [
        "# Get the day of the year (1-365)\n",
        "US_states_cases_tall['day_of_year'] = pd.to_datetime(US_states_cases_tall.date).dt.dayofyear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvcl0qutKD-5"
      },
      "source": [
        "# Get day of week, where 0=Monday and 6=Sunday\n",
        "US_states_cases_tall['day_of_week'] = pd.to_datetime(US_states_cases_tall.date).dt.weekday"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DfpTL-KE0-j"
      },
      "source": [
        "Let's turn these days of week as numbers into words with a very simple example of the `apply` function. The way that days of the week are represented work well with list indices, so we can just make a lookup list and write a simple function to apply it. This function is equivalent to using\n",
        "\n",
        "    lambda x: days[x]\n",
        "    \n",
        "as the function passed to the apply function, but I wanted to show this other approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUUiT4GIE2W1"
      },
      "source": [
        "days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMeeYaCwE4pE"
      },
      "source": [
        "def day_lookup(day_as_number):\n",
        "    return days[day_as_number]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4eHMjrTE61i"
      },
      "source": [
        "US_states_cases_tall['day_of_week_words'] = US_states_cases_tall.day_of_week.apply(day_lookup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Ap3tT-YM7l"
      },
      "source": [
        "# Get week of year (1-52)\n",
        "US_states_cases_tall[\"week_of_year\"] = pd.to_datetime(US_states_cases_tall.date).dt.isocalendar().week"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrHQ-nrTbWW4"
      },
      "source": [
        "# Get the month (1-12)\n",
        "US_states_cases_tall[\"month\"] = pd.to_datetime(US_states_cases_tall.date).dt.month"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu-BHPDXMgqR"
      },
      "source": [
        "A frequent statistic in COVID news is the case rate per 100,000 people, as a way of normalizing for population. We'll get this statistic for both the daily rates and the cumulative rates for each state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Kh7XK6rd7T"
      },
      "source": [
        "US_states_cases_tall[\"cases_rate_100K\"] = (US_states_cases_tall[\"cases_count_pos\"] / US_states_cases_tall[\"POP10\"]) * 1e5\n",
        "US_states_cases_tall[\"cases_cumulative_rate_100K\"] = (US_states_cases_tall[\"cases_cumulative\"] / US_states_cases_tall[\"POP10\"]) * 1e5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JnC9cVgfVmm"
      },
      "source": [
        "# We can admire our work now\n",
        "US_states_cases_tall.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCYTRWt5NCdA"
      },
      "source": [
        "US_states_cases_tall.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDSnmWC6usGs"
      },
      "source": [
        "# Now we can write out our data\n",
        "US_states_cases_tall.to_csv('US_states_cases_tall.csv', index=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}